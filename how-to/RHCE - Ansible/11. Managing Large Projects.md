# Managing Large Projects

## Selecting Hosts with Host Patterns

- Wildcards:
  We can use '*' to match multipule hosts. Notice that we have to surrond the host expression with ' to avoid shell expension problems. for example:

    ```yaml
    - name: blabla
      hosts: 'datacenter*'
    ```

- cutting host groups:
  We can perform an INNER-JOIN operation between a number of groups with the & simple.
  For example, to select hosts that are in the database AND usa groups:

    ```yaml
    - name: blabla
      hosts: 'database,&usa'
    ```

  We can perform a NOT operation between a number of groups with the ! simple.
  For example, to select hosts that are in the database NOT usa groups:

    ```yaml
    - name: blabla
      hosts: 'database,!usa'
    ```

## Managing Multiple Inventories

We cab use of multiple inventories in the same ansible run. If the location of the inventory is a directory then all inventory files included in the directory (static or dynamic) are combined to one inventory.

In general Inventory files should not depend on other inventory files.
But if needed we can use groups from on inventory on another inventory, this is usually useful when we have dynamic and static inventories. We don't want to rely on the parsing order of ansible so when we reference a group from inventory 1 on inventory 2 we must have a placeholder for the group in inventory 2.
For example, openshift-hosts comes from a dynamic inventory, so the static inventory shoudl look like:

```ini
[openshift-hosts]

[servers]
test.server.com

[servers:children]
openshift-hosts
```

This ensures that no matter the order in which inventory files are parsed, all of them are internally consistent.

NOTE

Ansible ignores files in an inventory directory if they end with certain suffixes. This can be controlled with the inventory_ignore_extensions directive in the Ansible configuration file. More information is available in the Ansible documentation.

## Configure Parallelism in Ansible Using Forks

When we run an ansible playbook, ansible performs each play/task on all managed hosts in order so that all hosts must successfully complete a task before any host starts the next task in the play.
Ansible could connect to all hosts in paralel to speed things up.
Note that if we target hundreds of hosts, this can put a heavy load on the control node.

The number of parallel connections can be set by:

- The forks parameter in the ansible.cfg file. It is set to 5 by default
- The -f or --forks option.
  
We can be verify the forks value by using one of the following:

```bash
[student@demo ~]$ grep forks ansible.cfg
forks          = 5
[student@demo ~]$ ansible-config dump |grep -i forks
DEFAULT_FORKS(default) = 5
[student@demo ~]$ ansible-config list |grep -i forks
DEFAULT_FORKS:
  description: Maximum number of forks Ansible will use to execute tasks on target
  - {name: ANSIBLE_FORKS}
  - {key: forks, section: defaults}
  name: Number of task forks
```

## Configure Batches in Ansible

When Ansible runs a play, it makes sure that all managed hosts have completed each task before starting the next task. In some cases this can lead to undesirable behavior.
For example, if a play updates a cluster of web servers, it might need to take each web server out of service while the update takes place. If all the servers are updated in the same play, they could all be out of service at the same time.

To avoid this problem we can use the serial keyword to run the play in batches. Each batch of hosts will be run through the entire play before the next batch is started.
The serial keyword can be specified as number or a percentage.
In the example below, Ansible executes the play on two managed hosts at a time. If either or both of those two hosts notified the handler, then Ansible runs the handler as needed for those two hosts.

```yaml
---
- name: Rolling update
  hosts: webservers
  serial: 2
  tasks:
  - name: latest apache httpd package is installed
    yum:
      name: httpd
      state: latest
    notify: restart apache

  handlers:
  - name: restart apache
    service:
      name: httpd
      state: restarted
```

IMPORTANT
Each batch of hosts counts as if it were a full play running on a subset of hosts. This means that if an entire batch fails, the play fails, which causes the entire playbook run to fail.

## Including or Importing Files

There are two operations that Ansible can use to bring content into a playbook:

- include content - dynamic operation, content is included during the run of the playbook.
- import content - static operation,  content is imported when the playbook is initially parsed, before the run starts.

### Importing Playbooks

We can import external playbooks into a main playbook with the import_playbook directive.
This approch is used when we have a large project and we want to create a main playbook that executes other playbooks.

Because the content being imported is a complete playbook, the import_playbook feature can only be used at the top level of a playbook and cannot be used inside a play. If you import multiple playbooks, then they will be imported and run in order.

A simple example of a main playbook that imports two additional playbooks is shown below:

```yaml
- name: Setup backend server
  import_playbook: backend.yml

- name: Setup database server
  import_playbook: db.yml
```

You can also import playbooks at the end of a playbook

```yaml
- name: Play 1
  hosts: localhost
  tasks:
    - debug:
        msg: Play 1

- name: Import Playbook
  import_playbook: play2.yml
```

### Importing and Including Task

You can import or include a list of tasks from a task file into a play.
A task file is a file that contains a flat list of tasks:

```ymal
[admin@node ~]$ cat webserver_tasks.yml
- name: Installs the httpd package
  yum:
    name: httpd
    state: latest

- name: Starts the httpd service
  service:
    name: httpd
    state: started
```

#### Importing Task Files

With import_tasks we can statically import a task file into a play inside a playbook. When you import a task file, the tasks in that file are directly inserted in the location of the import_tasks call when the playbook is parsed.

```ymal
---
- name: Install web server
  hosts: webservers
  tasks:
  - import_tasks: webserver_tasks.yml
```

When you import a task file, the tasks in that file are directly inserted when the playbook is parsed. Because import_tasks statically imports the tasks when the playbook is parsed, there are some effects on how it works.

Things to keep in maind whern importing tasks:

- When using the import_tasks with conditional statements (such as when), conditions are applied to each of the tasks.
- You cannot use loops with the import_tasks feature.
- If you use a variable to specify the name of the file to import, then you cannot use a host or group inventory variable.

#### Including Task Files

With include_tasks we can dynamically include a task file into a play inside a playbook.

```ymal
---
- name: Install web server
  hosts: webservers
  tasks:
  - include_tasks: webserver_tasks.yml
```

Things to keep in maind whern importing tasks:

- The include_tasks feature does not process content in the playbook until the play is running and that part of the play is reached.
- When using the include_tasks with conditional statements (such as when), set on the include determine whether or not the tasks are included in the play at all.
- If you run ansible-playbook --list-tasks to list the tasks in the playbook, then tasks in the included task files are not displayed. The tasks that include the task files are displayed.
- You cannot use ansible-playbook --start-at-task to start playbook execution from a task that is in an included task file.
- You cannot use a notify statement to trigger a handler name that is in an included task file. You can trigger a handler in the main playbook that includes an entire task file, in which case all tasks in the included file will run.

NOTE
You can find a more detailed discussion of the differences in behavior between import_tasks and include_tasks when conditionals are used at "Conditionals" in the Ansible User Guide.

Use Cases for Task Files:

- If new servers require complete configuration, then administrators could create various sets of tasks for creating users, installing packages, configuring services, configuring privileges, setting up access to a shared file system, hardening the servers, installing security updates, and installing a monitoring agent. Each of these sets of tasks could be managed through a separate self-contained task file.
I- f servers are managed collectively by the developers, the system administrators, and the database administrators, then every organization can write its own task file which can then be reviewed and integrated by the system manager.
- If a server requires a particular configuration, then it can be integrated as a set of tasks that are executed based on a conditional. In other words, including the tasks only if specific criteria are met.
- If a group of servers need to run a particular task or set of tasks, then the tasks might only be run on a server if it is part of a specific host group.
