# Cluster Maintenance

## OS Upgrades

When you upgrade a Kubernetes cluster then each node will be restarted with the upgraded OS.
If a node from a cluster goes down for any reason (including upgrade) then the pods on that node will not be accessible.
Kubernetes has a "pod eviction timeout" value set on the kubernetes controller manager and defaults to 5m, after the time has passed and the worker node is still not accessible then kubernetes will mark the worker as dead and if it will come back, it will come back with no pods.
If the pods were managed by a deployment or a replica set then K8S would have migrated them to other nodes in the cluster, but in case they were stand alone pods then they will just not appear in the cluster.

You can avoid that by manually draining the pods from a specific node before it is rebooted by using the drain command:

```bash
kubectl drain NODE-NAME
```

When you drain a node all the pods on the node are moved and the node is marked as UNSCHEDULABLE, even after the node is rebooted the UNSCHEDULABLE label remains and you need to manually remove it with the "uncordan" command:

```bash
kubectl uncordon NODE-NAME
```