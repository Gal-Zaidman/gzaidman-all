apiVersion: batch/v1
kind: Job
metadata:
  name: ocp-on-rhv-full-no-tests
  labels:
    jobgroup: ansible-runner
spec:
  backoffLimit: 0
  template:
    metadata:
      name: ocp-on-rhv-full-no-tests
      labels:
        jobgroup: ansible-runner
    spec:
      backoffLimit: 0
      terminationGracePeriodSeconds: 900
      containers:
      - name: lease
        image: registry.svc.ci.openshift.org/ci/boskoscli:latest
        terminationMessagePolicy: FallbackToLogsOnError
        resources:
          requests:
            cpu: 10m
            memory: 10Mi
          limits:
            memory: 200Mi
        volumeMounts:
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/shared/artifacts
        env:
        - name: CLUSTER_TYPE
          value: "ovirt"
        - name: CLUSTER_NAME
          value: "ovirt-manual-run"
        - name: LEASE_TYPE
          value: "conformance"


        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail

          trap 'rc=$?; CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi; if test "${rc}" -ne 0; then touch /tmp/shared/exit; fi; exit "${rc}"' EXIT

          # hack for bazel
          function boskosctl() {
            /app/boskos/cmd/cli/app.binary "${@}"
          }

          function extract_leases_info() {
            echo "$( jq ."${1}" --raw-output "${2}" )"
          }

          function acquire_lease() {
            resource="$( boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" acquire --type "${CLUSTER_TYPE}-quota-slice" --state "free" --target-state "leased" --timeout 150m )"
            resource_name="$(echo "${resource}"|jq .name --raw-output)"
            echo "[INFO] Lease acquired! at $(date --utc)"
            echo "[INFO] Leased resource: ${resource}"
            lease_path="/etc/openshift-installer/${resource_name}.json"
            ovirt_engine_template_name="$(extract_leases_info ovirt_engine_template_name ${lease_path})"
            echo "[INFO] Sending heartbeats to retain the lease ${resource_name}"
            boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" heartbeat --resource "${resource}" &
            heartbeats_pid=$!
            if [ "${LEASE_TYPE}" == "conformance" ]; then
              bm_name="$(extract_leases_info ovirt_engine_cluster_bm ${lease_path})"
              conformance_resource="$( boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" acquire --type "${CLUSTER_TYPE}-${bm_name}" --state "free" --target-state "leased" --timeout 150m )"
              conformance_resource_name="$(echo "${conformance_resource}"|jq .name --raw-output)"
              echo "[INFO] Conformance Lease acquired! at $(date --utc)"
              echo "[INFO] Conformance Leased resource: ${conformance_resource}"
              boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" heartbeat --resource "${resource}" &
              conformance_heartbeats_pid=$!
              echo "[INFO] Sending heartbeats to retain the lease ${conformance_resource_name}"
              worker_cpu=8
              worker_mem=16384
              master_cpu=8
              master_mem=16384
            else
              ovirt_engine_template_name="${ovirt_engine_template_name}-8G"
              worker_cpu=4
              worker_mem=8192
              master_cpu=4
              master_mem=8192
            fi
          }

          echo "[INFO] Acquiring a lease ..."
          acquire_lease

          #Saving parameters for the env
          cat > /tmp/shared/ovirt-lease.conf <<EOF
          OVIRT_APIVIP="$(extract_leases_info ovirt_apivip ${lease_path})"
          OVIRT_DNSVIP="$(extract_leases_info ovirt_dnsvip ${lease_path})"
          OVIRT_INGRESSVIP="$(extract_leases_info ovirt_ingressvip ${lease_path})"
          WORKER_CPU="${worker_cpu}"
          WORKER_MEM="${worker_mem}"
          MASTER_CPU="${master_cpu}"
          MASTER_MEM="${master_mem}"
          OCP_CLUSTER="$(extract_leases_info cluster_name ${lease_path})"
          OVIRT_ENGINE_CLUSTER_ID="$(extract_leases_info ovirt_engine_cluster_id ${lease_path})"
          OVIRT_ENGINE_TEMPLATE_NAME="${ovirt_engine_template_name}"
          EOF

          touch /tmp/shared/leased
          echo "[INFO] Lease acquired!"
          echo "[INFO] Leased resource: ${resource}"

          function release() {
              echo "killing heartbeat process "${heartbeats_pid}" at $(date --utc)"
              kill -9 "${heartbeats_pid}"
              echo "[INFO] Releasing the lease on resouce ${resource_name}"
              boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" release --name "${resource_name}" --target-state "free"
              if [ "${LEASE_TYPE}" == "conformance" ]; then
                echo "killing conformance heartbeats process "${conformance_heartbeats_pid}" at $(date --utc)"
                kill -9 "${conformance_heartbeats_pid}"
                echo "[INFO] Releasing the lease on resouce ${conformance_resource_name}"
                boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" release --name "${conformance_resource_name}" --target-state "free"
              fi
          }

          trap "release "${heartbeats_pid}"" EXIT
          trap 'release "${heartbeats_pid}"' TERM

          while true; do
            if [[ -f /tmp/shared/exit ]]; then
              echo "Another process exited" 2>&1
              exit 0
            fi

            sleep 15 & wait $!
          done




      - name: setup
        image: quay.io/openshift/origin-ovirt-installer:4.4
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/shared/artifacts
        env:
        - name: SSH_PUB_KEY_PATH
          value: /etc/openshift-installer/ssh-publickey
        - name: PULL_SECRET_PATH
          value: /etc/openshift-installer/pull-secret
        - name: USER
          value: test
        - name: HOME
          value: /tmp
        - name: OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE
          value: registry.svc.ci.openshift.org/ocp/release:4.4.0-0.ci-2020-04-08-183106
        command:
        - /bin/sh
        - -c
        - |
          #!/bin/sh
          trap 'rc=$?; if test "${rc}" -eq 0; then touch /tmp/shared/01_install.done; else touch /tmp/shared/01_install.exit; fi; exit "${rc}"' EXIT
          trap 'CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi' TERM

          ## Wait untill lease is acquired
          while true; do
          if [[ -f /tmp/shared/exit ]]; then
            echo "Another process exited" 2>&1
            exit 1
          fi
          if [[ -f /tmp/shared/leased ]]; then
            echo "Lease acquired, installing..."
            break
          fi
          sleep 15 & wait
          done

          cp "$(command -v openshift-install)" /tmp
          mkdir -p /tmp/shared/artifacts/installer

          ## update the IDs for new cluster
          source /tmp/shared/ovirt-lease.conf
          source /etc/openshift-installer/ovirt.conf

          export PATH=$PATH:/tmp/shared
          export EXPIRATION_DATE=$(date -d '4 hours' --iso=minutes --utc)
          export SSH_PUB_KEY=$(cat "${SSH_PUB_KEY_PATH}")
          export PULL_SECRET=$(cat "${PULL_SECRET_PATH}")
          export TF_VAR_ovirt_template_mem=${WORKER_MEM}
          export TF_VAR_ovirt_template_cpu=${WORKER_CPU}
          export TF_VAR_ovirt_master_mem=${MASTER_MEM}
          export TF_VAR_ovirt_master_cpu=${MASTER_CPU}

          #export OVIRT_CONFIG=/tmp/ovirt.conf
          ## Image handling - for now the CI uses a fixed rhcos template
          ## TODO - the fixed template is saving time and space when creating the
          ## cluster in the cost of having to maitain the supported version. This
          ## maintnance procedure does not exist yet.
          export OPENSHIFT_INSTALL_OS_IMAGE_OVERRIDE=${OVIRT_ENGINE_TEMPLATE_NAME}

          # We want the setup to download the latest CA from the engine
          # Therefor living it empty
          export OVIRT_CONFIG=/tmp/shared/artifacts/installer/ovirt-config.yaml
          cat > /tmp/shared/artifacts/installer/ovirt-config.yaml <<EOF
          ovirt_url: ${OVIRT_ENGINE_URL}
          ovirt_username: ${OVIRT_ENGINE_USERNAME}
          ovirt_password: ${OVIRT_ENGINE_PASSWORD}
          ovirt_cafile: ""
          ovirt_insecure: true
          EOF

          cat > /tmp/shared/artifacts/installer/install-config.yaml << EOF
          apiVersion: v1
          baseDomain: ${BASE_DOMAIN}
          metadata:
            name: ${OCP_CLUSTER}
          compute:
          - hyperthreading: Enabled
            name: worker
            platform: {}
            replicas: 2
          controlPlane:
            hyperthreading: Enabled
            name: master
            platform: {}
            replicas: 3
          platform:
            ovirt:
              ovirt_cluster_id: ${OVIRT_ENGINE_CLUSTER_ID}
              ovirt_storage_domain_id: ${OVIRT_ENGINE_STORAGE_DOMAIN_ID}
              api_vip: ${OVIRT_APIVIP}
              dns_vip: ${OVIRT_DNSVIP}
              ingress_vip: ${OVIRT_INGRESSVIP}
          pullSecret: >
            ${PULL_SECRET}
          sshKey: |
            ${SSH_PUB_KEY}
          EOF

          function update_image_registry() {
            while true; do
              sleep 10;
              oc get configs.imageregistry.operator.openshift.io/cluster >/dev/null 2>&1 && break
            done
            oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed","storage":{"emptyDir":{}}}}'
          }


          cd /tmp/shared/artifacts

          #download oc if missing
          if [ ! -f oc ] ; then
            echo "downloading oc binary"
            wget https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.4/linux/oc.tar.gz -O oc.tar.gz
            tar xvfz oc.tar.gz
            chmod +x ./oc
          fi
          export PATH=$PATH:/tmp/shared/artifacts

          TF_LOG=debug openshift-install --dir=/tmp/shared/artifacts/installer create ignition-configs --log-level=debug
          python -c \
              'import json, sys; j = json.load(sys.stdin); j[u"systemd"][u"units"] = [{u"contents": "[Unit]\nDescription=Mount etcd as a ramdisk\nBefore=local-fs.target\n[Mount]\n What=none\nWhere=/var/lib/etcd\nType=tmpfs\nOptions=size=2G\n[Install]\nWantedBy=local-fs.target", u"enabled": True, u"name":u"var-lib-etcd.mount"}]; json.dump(j, sys.stdout)' \
              </tmp/shared/artifacts/installer/master.ign \
              >/tmp/shared/artifacts/installer/master.ign.out
          mv /tmp/shared/artifacts/installer/master.ign.out /tmp/shared/artifacts/installer/master.ign

          export KUBECONFIG=/tmp/shared/artifacts/installer/auth/kubeconfig
          update_image_registry &

          # What we're doing here is we generate manifests first and force that OpenShift SDN is configured.
          TF_LOG=debug openshift-install --dir=/tmp/shared/artifacts/installer create manifests --log-level=debug
          TF_LOG=debug openshift-install --dir=/tmp/shared/artifacts/installer create cluster --log-level=debug &
          wait "$!"

          install_exit_status=$?
          sleep 360m
          exit $install_exit_status



      - name: run-conformance-tests
        image: 'registry.svc.ci.openshift.org/ovirt/openshift-tests:eslutsky'
        imagePullPolicy: IfNotPresent
        terminationMessagePolicy: FallbackToLogsOnError
        resources:
          requests:
            cpu: 1
            memory: 1Gi
          limits:
            memory: 7Gi
        command:
        - /bin/sh
        - -c
        - |
          #!/bin/bash
          sleep 360m


        volumeMounts:
        - name: config-gcp-secrets
          mountPath: /runner/gcp-secrets
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: installer-artifacts
          mountPath: /tmp/sharedartifacts
        - name: cluster-profile
          mountPath: /etc/openshift-installer

      - name: artifacts-pusher
        image: quay.io/eslutsky/ansible-runner
        #image: registry.svc.ci.openshift.org/ci/boskoscli
        #command: ["/bin/bash"]
        #args: ["-c","sleep 100000"]
        #args: ["apply","-auto-approve","ocp-on-rhv-ci"]
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail


          if [ `id -u` -ge 500 ]; then
              echo "runner:x:`id -u`:`id -g`:,,,:/runner:/bin/bash" > /tmp/passwd
              cat /tmp/passwd >> /etc/passwd
              rm /tmp/passwd
          fi


          echo "waiting for installlation and testing to complete..."

          # wait for the installation to finish
          for i in $(seq 1 180); do
            if [[ -f /tmp/shared/02_tests.done ]]; then
              break
            fi
            sleep 60 & wait
          done
          date

          source /tmp/shared/ovirt-lease.conf
          mkdir -p ~/.ssh/
          chmod 700 ~/.ssh/

          cat <<__EOF__ >>~/.ssh/config
          Host *
            StrictHostKeyChecking no
          __EOF__
          chmod 400 ~/.ssh/config

          #push artifacts for engine/ci for audit
          cd /tmp/shared/artifacts/
          if [ -f run_conformance.log ] ; then
            export ocp_cluster_id=$OCP_CLUSTER
            mkdir ${OCP_CLUSTER}/
            mv -f {run_conformance.log,junit,installer} ${OCP_CLUSTER}/
            ssh -i /runner/gcp-secrets/id_rsa centos@engine.rhv.gcp.devcluster.openshift.com "rm -rf /var/www/html/ci/${OVIRT_CLUSTER_NAME_P}"
            scp -i /runner/gcp-secrets/id_rsa  -r ${OCP_CLUSTER} centos@engine.rhv.gcp.devcluster.openshift.com:/var/www/html/ci/${OVIRT_CLUSTER_NAME_P}
          fi

          cd /tmp/scripts

          sleep 100000

          bash -x ./teardown-with-ansible.sh
          touch /tmp/shared/exit

        volumeMounts:
        - name: config-gcp-secrets
          mountPath: /runner/gcp-secrets
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: installer-artifacts
          mountPath: /tmp/shared/artifacts
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: scripts
          mountPath: /tmp/scripts
        env:
        - name: OVIRT_CLUSTER_NAME_P
          value: "ovirt05"

      volumes:
        - name: config-gcp-secrets
          secret:
            secretName: ovirt-infra-gcp-secrets

        - name: cluster-profile
          projected:
            sources:
            - secret:
                name: cluster-secrets-ovirt
            - secret:
                name: ovirt-infra-secrets

        - name: shared-tmp
          emptyDir: {}
        - name: installer-artifacts
          emptyDir: {}

        - name: scripts
          configMap:
            name: ocp-on-rhv-ci-scripts

      restartPolicy: Never
